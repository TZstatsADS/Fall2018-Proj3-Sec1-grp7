---
title: "Project 3 - Main Script of RandomForest"
author: "Hongru Liu hl3148"
date: "10/25/2018"
output: pdf_document
---

This file organizes all computational steps for single image super-resolution using **randomForest** method.

```{r}
if(!require("EBImage")){
  source("https://bioconductor.org/biocLite.R")
  biocLite("EBImage")
}

if(!require("randomForest")){
  install.packages("randomForest")
}

if(!require("h2o")){
  install.packages("h2o")
}

if(!require("caret")){
  install.packages("caret")
}

if(!require("doParallel")){
  install.packages("doParallel")
}

library("EBImage")
library("randomForest")
library("caret")
library("h2o")
library("doParallel")
```


### Step 0: specify directories.

Set the working directory to the image folder. Specify the training and the testing set. For data without an independent test/validation set, you need to create your own testing data by random subsampling. In order to obain reproducible results, set.seed() whenever randomization is used. 

```{r wkdir, eval=FALSE}
set.seed(2018)
#setwd("./ads_fall2018_proj3")
setwd("C:/Users/Albert/Desktop/Proj3-Sec1Group7/doc")
# here replace it with your own path or manually set it in RStudio to where this rmd file is located. 
# use relative path for reproducibility
```

Provide directories for training images. Low-resolution (LR) image set and High-resolution (HR) image set will be in different subfolders. 
```{r}
train_dir <- "../data/train_set/" # This will be modified for different data sets.
train_LR_dir <- paste(train_dir, "LR/", sep="")
train_HR_dir <- paste(train_dir, "HR/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="") 
```

### Step 1: set up controls for evaluation experiments.

In this chunk, we have a set of controls for the evaluation experiments. 

+ (T/F) cross-validation on the training set
+ (number) K, the number of CV folds
+ (T/F) process features for training set
+ (T/F) run evaluation on an independent test set
+ (T/F) process features for test set

```{r exp_setup}
run.feature.train=F # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
```

Using cross-validation or independent test set evaluation, we compare the performance of models with different specifications. In this project, we use randomForest with different `mtry`. In the following chunk, we list, in a vector, setups (in this case, `mtry`) corresponding to models that we will compare. 

```{r model_setup}
# define paremeter grid
hyper_grid.h2o <- list(
  ntrees = seq(200, 400, by = 100),
  mtries = c(1,3,5),
  sample_rate = c(.55, .632, .70))
# define grid search path
search_criteria <- list(
  strategy = "RandomDiscrete",
  stopping_metric = "mse",
  stopping_tolerance = 0.005,
  stopping_rounds = 10,
  max_runtime_secs = 30*60)
```

### Step 2: import training images class labels.

We provide extra information of image label: car (0), flower (1), market (2). These labels are not necessary for your model.

```{r train_label}
train_label_path <- "C:/Users/Albert/Desktop/Proj3-Sec1Group7/data/train_set/label.csv"
extra_label <- read.csv(train_label_path, colClasses=c("NULL", NA, NA))
```

### Step 3: construct features and responses

`feature.R` should be the wrapper for all your feature engineering functions and options. The function `feature( )` should have options that correspond to different scenarios for your project and produces an R object that contains features and responses that are required by all the models you are going to evaluate later. 
+ `feature.R`
  + Input: a path for low-resolution images.
  + Input: a path for high-resolution images.
  + Output: an RData file that contains extracted features and corresponding responses

```{r feature}
source("../lib/feature.R")

tm_feature_train <- NA
if(run.feature.train){
  tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
  feat_train <- dat_train$feature
  label_train <- dat_train$label
  save(dat_train, file="../output/feature_train_rf.RData")
}
```


### Step 4: Train a prediction model with training images
Call the train model and test model from library. 

`tune_rf.R` and `test_rf.R` should be wrappers for all your model training steps and your prediction steps. 
+ `tune_rf.R`
  + Input: a path that points to the training set features and responses.
  + Output: an RData file that contains trained classifiers in the forms of R objects: models/settings/links to external trained configurations.
+ `test_rf.R`
  + Input: a path that points to the test set features.
  + Input: an R object that contains a trained classifier.
  + Output: an R object of response predictions on the test set. If there are multiple classifiers under evaluation, there should be multiple sets of label predictions. 
```{r loadlib}
source("../lib/RandomForest/tune_rf.R")
source("../lib/RandomForest/test_rf.R")
```

* Train the model with the entire training set using the selected model (model parameter)
```{r}
if(!run.feature.train) {
  load("C:/Users/Albert/Desktop/Proj3-Sec1Group7/output/feature_train_rf.Rdata")
  feat_train <- dat_train$feature
  label_train <- dat_train$label
}

tm_train=NA
tm_train <- system.time(fit_train_rf <- train_rf(feat_train, label_train, hyper_grid.h2o, search_criteria))
save(fit_train_rf, file="../output/fit_train_rf.RData")
```

### Step 5: Super-resolution for test images
Feed the final training model with the completely holdout testing data. 
+ `superResolution.R`
  + Input: a path that points to the folder of low-resolution test images.
  + Input: a path that points to the folder (empty) of high-resolution test images.
  + Input: an R object that contains tuned predictors.
  + Output: construct high-resolution versions for each low-resolution test image.
```{r superresolution}
source("../lib/superResolution.R")
test_dir <- "../data/test_set/" # This will be modified for different data sets.
test_LR_dir <- paste(test_dir, "LR/", sep="")
test_HR_dir <- paste(test_dir, "HR/", sep="")

tm_test=NA
if(run.test){
  load(file="../output/fit_train.RData")
  tm_test <- system.time(superResolution(test_LR_dir, test_HR_dir, fit_train))
}
```

### Summarize Running Time
Prediction performance matters, so does the running times for constructing features and for training the model, especially when the computation resource is limited. 
```{r running_time}
cat("Time for constructing training features =", tm_feature_train[1], "s \n")
#cat("Time for constructing testing features =", tm_feature_test[1], "s \n")
cat("Time for training model =", tm_train[1], "s \n")
cat("Time for super-resolution =", tm_test[1], "s \n")
```

